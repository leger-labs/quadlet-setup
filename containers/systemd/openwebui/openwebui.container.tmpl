# Generated by Chezmoi - DO NOT EDIT MANUALLY

[Unit]
Description=Open WebUI - AI Chat Interface
After=network-online.target llm.network.service
After=litellm.service openwebui-postgres.service openwebui-redis.service searxng.service docling.service jupyter.service qdrant.service
Requires=llm.network.service
Wants=litellm.service openwebui-postgres.service openwebui-redis.service searxng.service docling.service jupyter.service qdrant.service

[Container]
Image=ghcr.io/open-webui/open-webui:main
AutoUpdate=registry
ContainerName=openwebui

# Network
Network=llm.network

# Published port for Caddy to access
PublishPort={{ .published_ports.openwebui }}:{{ .ports.openwebui }}

# Volume
Volume=openwebui.volume:/app/backend/data:Z

# Environment from service-specific config file
EnvironmentFile=%h/.config/containers/systemd/openwebui/openwebui.env

# Health check
HealthCmd="wget --no-verbose --tries=1 --spider http://localhost:{{ .ports.openwebui }}/health || exit 1"
HealthInterval=30s
HealthTimeout=5s
HealthRetries=3
HealthStartPeriod=30s

[Service]
Slice=llm.slice
TimeoutStartSec=900
Restart=on-failure
RestartSec=10

[Install]
WantedBy=scroll-session.target
