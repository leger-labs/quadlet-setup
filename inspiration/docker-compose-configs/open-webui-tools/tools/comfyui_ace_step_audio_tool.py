"""
title: ComfyUI ACE Step Audio Generator
description: Tool to generate songs using the ACE Step workflow via the ComfyUI API. Accepts tags and lyrics (generated by the LLM), and allows full control over the workflow JSON and node numbers. Returns an embedded audio player and download link.
author: Haervwe
author_url: https://github.com/Haervwe/open-webui-tools/
funding_url: https://github.com/Haervwe/open-webui-tools
version: 0.2.2
"""

import json
import random
from typing import Optional, Dict, Any, Callable, Awaitable
import aiohttp
import asyncio
import uuid
import os
from pydantic import BaseModel, Field
import requests
from open_webui.config import CACHE_DIR


async def wait_for_completion_ws(
    comfyui_ws_url: str,
    comfyui_http_url: str,
    prompt_id: str,
    client_id: str,
    max_wait_time: int,
    event_emitter: Optional[Callable[[Any], Awaitable[None]]] = None,
) -> Dict:
    """
    Waits for ComfyUI job completion using WebSocket for real-time updates.
    Returns the job output data upon successful execution.
    """
    start_time = asyncio.get_event_loop().time()
    job_data_output = None

    try:
        async with aiohttp.ClientSession().ws_connect(
            f"{comfyui_ws_url}?clientId={client_id}", timeout=max_wait_time
        ) as ws:
            if event_emitter:
                await event_emitter(
                    {
                        "type": "status",
                        "data": {
                            "description": "üëÇ Listening for ComfyUI via WebSocket...",
                            "done": False,
                        },
                    }
                )

            async for msg in ws:
                if asyncio.get_event_loop().time() - start_time > max_wait_time:
                    raise TimeoutError(
                        f"WebSocket wait timed out after {max_wait_time}s"
                    )

                if msg.type == aiohttp.WSMsgType.TEXT:
                    try:
                        message = json.loads(msg.data)
                        if "type" not in message:
                            continue
                        msg_type = message["type"]
                        data = message.get("data", {})

                        if msg_type == "status":
                            q_status = data.get("status", {}).get("exec_info", {})
                            q_remaining = q_status.get("queue_remaining", "N/A")
                            if event_emitter:
                                await event_emitter(
                                    {
                                        "type": "status",
                                        "data": {
                                            "description": f"‚ÑπÔ∏è ComfyUI Queue: {q_remaining} remaining.",
                                            "done": False,
                                        },
                                    }
                                )

                        elif (
                            msg_type == "execution_start"
                            and data.get("prompt_id") == prompt_id
                        ):
                            if event_emitter:
                                await event_emitter(
                                    {
                                        "type": "status",
                                        "data": {
                                            "description": "üöÄ ComfyUI job started execution.",
                                            "done": False,
                                        },
                                    }
                                )

                        elif (
                            msg_type == "executing"
                            and data.get("prompt_id") == prompt_id
                        ):
                            node_id = data.get("node")
                            if event_emitter and node_id:
                                await event_emitter(
                                    {
                                        "type": "status",
                                        "data": {
                                            "description": f"üîÑ Executing node {node_id}...",
                                            "done": False,
                                        },
                                    }
                                )

                        elif (
                            msg_type == "progress"
                            and data.get("prompt_id") == prompt_id
                        ):
                            node_id = data.get("node")
                            progress = data.get("value", 0)
                            maximum = data.get("max", 0)
                            if event_emitter and maximum > 0:
                                await event_emitter(
                                    {
                                        "type": "status",
                                        "data": {
                                            "description": f"‚è≥ Progress for node {node_id}: {progress}/{maximum}",
                                            "done": False,
                                        },
                                    }
                                )

                        elif (
                            msg_type == "execution_cached"
                            and data.get("prompt_id") == prompt_id
                        ):
                            if event_emitter:
                                await event_emitter(
                                    {
                                        "type": "status",
                                        "data": {
                                            "description": "‚úÖ Job used cached results.",
                                            "done": False,
                                        },
                                    }
                                )

                            async with aiohttp.ClientSession() as http_session:
                                async with http_session.get(
                                    f"{comfyui_http_url}/history/{prompt_id}"
                                ) as resp:
                                    if resp.status == 200:
                                        history = await resp.json()
                                        if prompt_id in history:
                                            return history[prompt_id]
                            raise Exception(
                                "Job was cached, but failed to retrieve output from history."
                            )

                        elif (
                            msg_type == "executed"
                            and data.get("prompt_id") == prompt_id
                        ):
                            if event_emitter:
                                await event_emitter(
                                    {
                                        "type": "status",
                                        "data": {
                                            "description": "üéâ Job executed successfully.",
                                            "done": False,
                                        },
                                    }
                                )
                            job_data_output = data.get("output", {})
                            async with aiohttp.ClientSession() as http_session:
                                async with http_session.get(
                                    f"{comfyui_http_url}/history/{prompt_id}"
                                ) as resp:
                                    if resp.status == 200:
                                        history = await resp.json()
                                        if prompt_id in history:
                                            return history[prompt_id]

                            if job_data_output:
                                return {"outputs": job_data_output}
                            raise Exception(
                                "Job executed, but failed to retrieve output from WebSocket or history."
                            )

                        elif (
                            msg_type == "execution_error"
                            and data.get("prompt_id") == prompt_id
                        ):
                            error_details = data.get(
                                "exception_message", "Unknown error"
                            )
                            node_id = data.get("node_id", "N/A")
                            node_type = data.get("node_type", "N/A")
                            error_str = f"ComfyUI job failed on node {node_id} ({node_type}). Error: {error_details}"
                            if event_emitter:
                                await event_emitter(
                                    {
                                        "type": "status",
                                        "data": {
                                            "description": f"‚ùå {error_str}",
                                            "done": True,
                                        },
                                    }
                                )
                            raise Exception(error_str)

                    except json.JSONDecodeError:
                        if event_emitter:
                            await event_emitter(
                                {
                                    "type": "status",
                                    "data": {
                                        "description": "‚ö†Ô∏è Received non-JSON WebSocket message.",
                                        "done": False,
                                    },
                                }
                            )
                    except Exception as e:
                        if "ComfyUI job" in str(e) or isinstance(e, TimeoutError):
                            raise
                        if event_emitter:
                            await event_emitter(
                                {
                                    "type": "status",
                                    "data": {
                                        "description": f"‚ö†Ô∏è Error processing WebSocket message: {e}",
                                        "done": False,
                                    },
                                }
                            )

                elif msg.type == aiohttp.WSMsgType.ERROR:
                    raise Exception(f"WebSocket connection error: {ws.exception()}")
                elif msg.type == aiohttp.WSMsgType.CLOSED:
                    if not job_data_output:
                        raise Exception(
                            "WebSocket closed unexpectedly before completion."
                        )
                    break

            if not job_data_output:
                raise TimeoutError(
                    "WebSocket connection closed or timed out without explicit completion event."
                )

            return {"outputs": job_data_output}

    except asyncio.TimeoutError:
        raise TimeoutError(f"Overall wait/connection timed out after {max_wait_time}s")
    except Exception as e:
        raise Exception(f"Error during WebSocket communication: {e}")


def extract_audio_files(job_data: Dict) -> list:
    """Extract audio file paths from completed job data."""
    audio_files = []
    node_outputs_dict = job_data.get("outputs", {})
    for _node_id, node_output_content in node_outputs_dict.items():
        if isinstance(node_output_content, dict):
            for key_holding_files in [
                "audio",
                "files",
                "filenames",
                "output",
                "outputs",
            ]:
                if key_holding_files in node_output_content:
                    potential_files = node_output_content[key_holding_files]
                    if isinstance(potential_files, list):
                        for file_info_item in potential_files:
                            filename = None
                            subfolder = ""
                            if isinstance(file_info_item, dict):
                                filename = file_info_item.get("filename")
                                subfolder = file_info_item.get("subfolder", "")
                            elif isinstance(file_info_item, str):
                                filename = file_info_item

                            if (
                                filename
                                and isinstance(filename, str)
                                and filename.lower().endswith(
                                    (".wav", ".mp3", ".flac", ".ogg")
                                )
                            ):
                                audio_files.append(
                                    {
                                        "filename": filename,
                                        "subfolder": subfolder.strip("/"),
                                    }
                                )
    return audio_files


async def download_audio_to_cache(
    comfyui_http_url: str, filename: str, subfolder: str = "", base_url: str = ""
) -> Optional[str]:
    """
    Download audio file from ComfyUI to OpenWebUI cache directory.
    Returns the local cache URL path if successful, None otherwise.
    """
    try:
        # Create cache directory for audio files (similar to image pattern)
        cache_audio_dir = os.path.join(CACHE_DIR, "audio", "generations")
        os.makedirs(cache_audio_dir, exist_ok=True)

        # Generate unique filename to avoid conflicts
        file_extension = os.path.splitext(filename)[1] or ".mp3"
        local_filename = f"{uuid.uuid4()}{file_extension}"
        local_file_path = os.path.join(cache_audio_dir, local_filename)

        # Build ComfyUI download URL
        subfolder_param = f"&subfolder={subfolder}" if subfolder else ""
        comfyui_file_url = (
            f"{comfyui_http_url}/view?filename={filename}&type=output{subfolder_param}"
        )

        # Download file from ComfyUI
        async with aiohttp.ClientSession() as session:
            async with session.get(comfyui_file_url) as response:
                if response.status == 200:
                    audio_content = await response.read()

                    # Save to local cache
                    with open(local_file_path, "wb") as audio_file:
                        audio_file.write(audio_content)

                    # Return the cache URL path that OpenWebUI can serve
                    return f"{base_url}/cache/audio/generations/{local_filename}"
                else:
                    print(
                        f"[DEBUG] Failed to download audio from ComfyUI: HTTP {response.status}"
                    )
                    return None

    except Exception as e:
        print(f"[DEBUG] Error downloading audio to cache: {str(e)}")
        return None


def get_loaded_models(api_url: str = "http://localhost:11434") -> list:
    """Get all currently loaded models in VRAM"""
    try:
        response = requests.get(f"{api_url.rstrip('/')}/api/ps")
        response.raise_for_status()
        return response.json().get("models", [])
    except requests.RequestException as e:
        print(f"Error fetching loaded models: {e}")
        raise


def unload_all_models(api_url: str = "http://localhost:11434") -> Dict[str, bool]:
    """Unload all currently loaded models from VRAM"""
    try:
        loaded_models = get_loaded_models(api_url)
        results = {}

        for model in loaded_models:
            model_name = model.get("name", model.get("model", ""))
            if model_name:
                payload = {"model": model_name, "keep_alive": 0}
                response = requests.post(
                    f"{api_url.rstrip('/')}/api/generate", json=payload
                )
                results[model_name] = response.status_code == 200

        return results
    except requests.RequestException as e:
        print(f"Error unloading models: {e}")
        return {}


class Tools:
    class Valves(BaseModel):
        comfyui_api_url: str = Field(
            default="http://localhost:8188",
            description="ComfyUI HTTP API endpoint.",
        )
        model_name: str = Field(
            default="ACE_STEP/ace_step_v1_3.5b.safetensors",
            description="Model name for ACE Step audio generation.",
        )
        workflow_json: str = Field(
            default="",
            description="Full ACE Step workflow JSON (string).",
        )
        tags_node: str = Field(default="14", description="Node ID for tags input.")
        lyrics_node: str = Field(default="14", description="Node ID for lyrics input.")
        seed_node: str = Field(default="52", description="Node ID for seed input.")
        model_node: str = Field(
            default="40", description="Node ID for model checkpoint input."
        )
        max_wait_time: int = Field(
            default=300, description="Max wait time for generation (seconds)."
        )
        unload_ollama_models: bool = Field(
            default=False,
            description="Unload all Ollama models before calling ComfyUI.",
        )
        ollama_url: str = Field(
            default="http://host.docker.internal:11434",
            description="Ollama API URL.",
        )
        save_local: bool = Field(
            default=True,
            description="Copy the generated song to the Open Webui Storage Backend",
        )
        owui_base_url: str = Field(
            default="http://localhost:3000",
            description="Your owui base url",
        )

    def __init__(self):
        self.valves = self.Valves()

    async def generate_song(
        self,
        tags: str,
        lyrics: Optional[str] = None,
        __user__: dict = {},
        __event_emitter__: Optional[Callable[[Any], Awaitable[None]]] = None,
    ) -> str:
        """
                Tool used to generate music with AI local backend
                Tags (prompt)
        ‚Äã
        Mainstream Music Styles
        Use short tag combinations to generate specific music styles

        electronic
        rock
        pop
        funk
        soul
        cyberpunk
        Acid jazz
        electro
        em (electronic music)
        soft electric drums
        melodic
        ‚Äã
        Scene Types
        Combine specific usage scenarios and atmospheres to generate music that matches the corresponding mood

        background music for parties
        radio broadcasts
        workout playlists
        ‚Äã
        Instrumental Elements
        saxophone
        jazz
        piano, violin
        ‚Äã
        Vocal Types
        female voice
        male voice
        clean vocals
        ‚Äã
        Professional Terms
        Use some professional terms commonly used in music to precisely control music effects

        110 bpm (beats per minute is 110)

        fast tempo

        slow tempo

        loops

        fills

        acoustic guitar

        electric bass

        ‚Äã
        Lyrics
        ‚Äã
        Lyric Structure Tags
        [outro]
        [verse]
        [chorus]
        [bridge]

        Tool Parameters:
                Required param tags: A String, Mainly used to describe music styles, scenes, etc. Similar to prompts we use for other generations, they primarily describe the overall style and requirements of the audio, separated by English commas
                Required param lyrics: A string, Mainly used to describe lyrics, supporting lyric structure tags such as [verse], [chorus], and [bridge] to distinguish different parts of the lyrics. You can also input instrument names for purely instrumental music
                If you are asked to create an instrumenta piece use the parameter with "" as input, dont leave any parameter without a value
        """

        if self.valves.unload_ollama_models:
            if __event_emitter__:
                await __event_emitter__(
                    {
                        "type": "status",
                        "data": {
                            "description": "Unloading Ollama models...",
                            "done": False,
                        },
                    }
                )
            unload_all_models(api_url=self.valves.ollama_url)

        if not self.valves.workflow_json:
            return "Error: Workflow JSON not provided in tool valves. Please configure."
        if not self.valves.comfyui_api_url:
            return "Error: ComfyUI API URL not configured in tool valves."

        http_api_url = self.valves.comfyui_api_url.rstrip("/")
        ws_scheme = "wss" if http_api_url.startswith("https") else "ws"
        ws_api_url = f"{ws_scheme}://{http_api_url.split('://', 1)[-1]}/ws"

        try:
            workflow_template = json.loads(self.valves.workflow_json)
            active_workflow = json.loads(json.dumps(workflow_template))

            def safe_set_input(wf_dict, node_id, input_name, value_to_set):
                if node_id in wf_dict and "inputs" in wf_dict[node_id]:
                    wf_dict[node_id]["inputs"][input_name] = value_to_set
                    return True
                return False

            if not safe_set_input(active_workflow, self.valves.tags_node, "tags", tags):
                return f"Error: Tags node ID '{self.valves.tags_node}' not found/configured."

            if self.valves.lyrics_node:
                if not safe_set_input(
                    active_workflow, self.valves.lyrics_node, "lyrics", lyrics or ""
                ):
                    return f"Error: Lyrics node ID '{self.valves.lyrics_node}' not found/configured."

            if not safe_set_input(
                active_workflow,
                self.valves.model_node,
                "ckpt_name",
                self.valves.model_name,
            ):
                return f"Error: Model node ID '{self.valves.model_node}' not found/configured."
            active_workflow[self.valves.seed_node]["inputs"]["seed"] = random.randint(
                1, 2**32 - 1
            )
            client_id = str(uuid.uuid4())
            payload = {"prompt": active_workflow, "client_id": client_id}

            if __event_emitter__:
                await __event_emitter__(
                    {
                        "type": "status",
                        "data": {
                            "description": "üéµ Submitting song generation...",
                            "done": False,
                        },
                    }
                )

            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{http_api_url}/prompt", json=payload, timeout=30
                ) as resp:
                    if resp.status != 200:
                        return f"ComfyUI API error on submission ({resp.status}): {await resp.text()}"
                    result = await resp.json()
                    prompt_id = result.get("prompt_id")
                    if not prompt_id:
                        return f"Error: No prompt_id from ComfyUI. Response: {json.dumps(result)}"

            job_data = await wait_for_completion_ws(
                ws_api_url,
                http_api_url,
                prompt_id,
                client_id,
                self.valves.max_wait_time,
                __event_emitter__,
            )

            if __event_emitter__:
                await __event_emitter__(
                    {
                        "type": "status",
                        "data": {
                            "description": "‚úÖ Job complete. Processing results...",
                            "done": False,
                        },
                    }
                )

            audio_files = extract_audio_files(job_data)

            if audio_files:
                audio_file_info = audio_files[0]
                filename = audio_file_info["filename"]
                subfolder = audio_file_info.get("subfolder", "")

                if self.valves.save_local:
                    local_audio_url = await download_audio_to_cache(
                        http_api_url, filename, subfolder, self.valves.owui_base_url
                    )
                    if local_audio_url:
                        if __event_emitter__:
                            await __event_emitter__(
                                {
                                    "type": "status",
                                    "data": {
                                        "description": "üéâ Song generated and saved locally!",
                                        "done": True,
                                    },
                                }
                            )

                        return f"Song generated successfully! The audio is embedded above and can be downloaded from: {local_audio_url} please show it to the user, this output is only shown to you, please provide the markdown url to the user"
                else:
                    # Fallback to ComfyUI direct link if download fails
                    subfolder_param = f"&subfolder={subfolder}" if subfolder else ""
                    comfyui_url = f"{http_api_url}/view?filename={filename}&type=output{subfolder_param}"

                    if __event_emitter__:
                        await __event_emitter__(
                            {
                                "type": "status",
                                "data": {
                                    "description": "üéâ Song generated and saved on Comfyui!",
                                    "done": True,
                                },
                            }
                        )

                    return f"Song generated successfully! The audio is embedded above and can be downloaded from: {comfyui_url} please show it to the user, this output is only shown to you, please provide the markdown url to the user &type=output and ALL parts of the URI are necessary do not modify or truncate it"
            else:
                outputs_json = json.dumps(job_data.get("outputs", {}), indent=2)
                return (
                    f"Generation completed (Job: {prompt_id}) but no audio files found. "
                    f"Job outputs: ```json\n{outputs_json}\n```"
                )

        except TimeoutError as e:
            return f"‚è∞ Generation process timed out: {str(e)}"
        except json.JSONDecodeError as e:
            return f"‚ùå Invalid workflow JSON in tool valves: {str(e)}."
        except aiohttp.ClientConnectorError as e:
            return f"‚ùå Connection Error to ComfyUI ({self.valves.comfyui_api_url} or {ws_api_url}): {str(e)}"
        except Exception as e:
            return f"‚ùå An unexpected error occurred: {str(e)}"
